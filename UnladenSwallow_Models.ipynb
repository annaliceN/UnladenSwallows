{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UnladenSwallow_Models",
      "provenance": [],
      "collapsed_sections": [
        "fJoluWpQefKq",
        "ZGoI1ni7ZxrJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRzPDiVzsyGz"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS5Ch2HbC6Gb"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "checkpoints = '/content/drive/MyDrive/colab_files/birds/'\n",
        "if not os.path.exists(checkpoints):\n",
        "    os.makedirs(checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZafXD_YHIGI0"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYJ6ZE1CuGth"
      },
      "source": [
        "import os\n",
        "if not os.path.exists('birds21wi'):\n",
        "    !mkdir birds21wi\n",
        "    os.chdir('birds21wi')\n",
        "    !wget https://pjreddie.com/media/files/birds/train.tar\n",
        "    !wget https://pjreddie.com/media/files/birds/test.tar\n",
        "    !wget https://pjreddie.com/media/files/birds/names.txt\n",
        "    !tar xf train.tar\n",
        "    !tar xf test.tar\n",
        "    !mkdir testing\n",
        "    !mv test testing\n",
        "    os.chdir('..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sNQBsQiszKj"
      },
      "source": [
        "def get_bird_data(augmentation=0):\n",
        "    val_ratio = 0.1  # make validation set 10% of training set size\n",
        "\n",
        "    # original size: 128\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomCrop(224, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n",
        "        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    transform_val = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomCrop(224, padding=8, padding_mode='edge'), # Take 128x128 crops from padded images\n",
        "        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    \n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # load training dataset\n",
        "    trainset = torchvision.datasets.ImageFolder(root='birds21wi/train', transform=transform_train)\n",
        "\n",
        "    # create class organizers\n",
        "    classes = open(\"birds21wi/names.txt\").read().strip().split(\"\\n\")\n",
        "    class_to_idx = trainset.class_to_idx\n",
        "    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n",
        "    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n",
        "\n",
        "    # split training set into training and validation set\n",
        "    valset_len = int(len(trainset) * val_ratio)\n",
        "    trainset_len = len(trainset) - valset_len\n",
        "    valset, trainset = torch.utils.data.random_split(trainset, [valset_len, trainset_len])\n",
        "\n",
        "    # create train and val loaders\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "    valloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    # load test dataset\n",
        "    testset = torchvision.datasets.ImageFolder(root='birds21wi/testing', transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(\"Trainset length: \", trainset_len)\n",
        "    print(\"Valset length: \", valset_len)\n",
        "    print(\"Testset length: \", len(testset))\n",
        "\n",
        "    \n",
        "    return {'train': trainloader, 'test': testloader, 'val': valloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n",
        "\n",
        "data = get_bird_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGbbBNQVaO6G"
      },
      "source": [
        "print(data['to_class'])\n",
        "print(data['to_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llHSMv7js5yA"
      },
      "source": [
        "dataiter = iter(data['train'])\n",
        "images, labels = dataiter.next()\n",
        "images = images[:8]\n",
        "print(images.size())\n",
        "\n",
        "val_iter = iter(data['val'])\n",
        "val_images, val_labels = val_iter.next()\n",
        "val_images = val_images[:8]\n",
        "print(val_images.size())\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# show images\n",
        "print(\"Training set\")\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(\"Labels:\" + ', '.join('%9s' % data['to_name'][labels[j].item()] for j in range(8)))\n",
        "\n",
        "# show images\n",
        "print(\"Validation set\")\n",
        "imshow(torchvision.utils.make_grid(val_images))\n",
        "# print labels\n",
        "print(\"Labels:\" + ', '.join('%9s' % data['to_name'][val_labels[j].item()] for j in range(8)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCXgdBQSU1Rb"
      },
      "source": [
        "# Training + Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5_LglWCs9Iu"
      },
      "source": [
        "def train(net, dataloader, val_dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n",
        "          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n",
        "    net.to(device)\n",
        "    # net.train()\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    valset_len = 3856\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
        "\n",
        "    # Load previous training state\n",
        "    if state:\n",
        "        net.load_state_dict(state['net'])\n",
        "        optimizer.load_state_dict(state['optimizer'])\n",
        "        start_epoch = state['epoch']\n",
        "        losses = state['losses']\n",
        "\n",
        "    # Fast forward lr schedule through already trained epochs\n",
        "    for epoch in range(start_epoch):\n",
        "        if epoch in schedule:\n",
        "            print (\"Learning rate: %f\"% schedule[epoch])\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = schedule[epoch]\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        sum_loss = 0.0\n",
        "\n",
        "        print(\"Training for epoch: \", epoch)\n",
        "        # Update learning rate when scheduled\n",
        "        if epoch in schedule:\n",
        "            print (\"Learning rate: %f\"% schedule[epoch])\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = schedule[epoch]\n",
        "\n",
        "        # training data\n",
        "        for i, batch in enumerate(dataloader, 0):\n",
        "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()  # autograd magic, computes all the partial derivatives\n",
        "            optimizer.step() # takes a step in gradient direction\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            sum_loss += loss.item()\n",
        "\n",
        "            if i % print_every == print_every-1:\n",
        "                if verbose:\n",
        "                  print('[%d, %5d] train loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n",
        "                sum_loss = 0.0\n",
        "        \n",
        "        print()\n",
        "        # ------------------------------------------------------------------------\n",
        "        val_sum_loss = 0.0\n",
        "        val_running_correct = 0.0\n",
        "\n",
        "        print(\"Validation for epoch: \", epoch)\n",
        "        # validation data\n",
        "        for i, batch in enumerate(val_dataloader, 0):\n",
        "          inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          with torch.set_grad_enabled(False):\n",
        "            outputs = net(inputs)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "          val_losses.append(val_loss.item())\n",
        "          val_sum_loss += val_loss.item()\n",
        "          val_running_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "          if i % print_every == print_every-1:\n",
        "              if verbose:\n",
        "                print('[%d, %5d] val loss: %.3f' % (epoch, i + 1, val_sum_loss / print_every))\n",
        "              val_sum_loss = 0.0\n",
        "       \n",
        "        # print validation accuracy per epoch\n",
        "        val_epoch_acc = val_running_correct.double() / valset_len\n",
        "        print(\"Val Accuracy: {:.4f}\".format(val_epoch_acc))\n",
        "        print()\n",
        "\n",
        "        if checkpoint_path:\n",
        "            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n",
        "            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n",
        "\n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH3jOjwkvAZN"
      },
      "source": [
        "def predict(net, dataloader, ofname):\n",
        "    out = open(ofname, 'w')\n",
        "    out.write(\"path,class\\n\")\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(dataloader, 0):\n",
        "            if i%100 == 0:\n",
        "                print(i)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            fname, _ = dataloader.dataset.samples[i]\n",
        "            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n",
        "    out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJoluWpQefKq"
      },
      "source": [
        "# ResNet18 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cwn8-9BUUOq"
      },
      "source": [
        "## ResNet18 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ-yKtWUu-OE"
      },
      "source": [
        "resnet = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet, data['train'], data['val'], epochs=5, lr=.001, decay=.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciUXCJ5LvN1p"
      },
      "source": [
        "resnet = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet, data['train'], data['val'], epochs=10, schedule={0:.01, 8:.001}, lr=.01, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVyblLspSFnU"
      },
      "source": [
        "def smooth(x, size):\n",
        "  return np.convolve(x, np.ones(size)/size, mode='valid')\n",
        "plt.plot(smooth(losses,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBL4BRptyt5v"
      },
      "source": [
        "state = torch.load(checkpoints + 'checkpoint-6.pkl')\n",
        "plt.plot(smooth(state['losses'], 50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0FYBWLXUmni"
      },
      "source": [
        "## ResNet18 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_doagLCS9u0"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "resnet.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-6.pkl')\n",
        "resnet.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "predict(resnet, data['test'], checkpoints + \"preds.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LIv4TiHM7mI"
      },
      "source": [
        "# ResNet34 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI-WZHuCNCdj"
      },
      "source": [
        "## ResNet34 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkg3qp_hNOIb"
      },
      "source": [
        "resnet34 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet34', pretrained=True)\n",
        "resnet34.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet34, data['train'], data['val'], epochs=5, lr=.001, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wnoadZNenK"
      },
      "source": [
        "resnet34 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet34', pretrained=True)\n",
        "resnet34.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet34, data['train'], data['val'], epochs=10, lr=.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KpMTl7JNHPV"
      },
      "source": [
        "## ResNet34 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD4ysUXBN0D0"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet34 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet34', pretrained=True)\n",
        "resnet34.fc = nn.Linear(512, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "resnet34.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "predict(resnet34, data['test'], checkpoints + \"preds.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGoI1ni7ZxrJ"
      },
      "source": [
        "# ResNet50 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brdeWwHrUY0L"
      },
      "source": [
        "## ResNet50 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R6Ii1HOaob7"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=5, lr=.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vtUn8mya3jZ"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=10, lr=.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQPhDlRIddcs"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=20, schedule={0:.001, 4:.0001}, lr=.001, decay=0.005, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I5MnlkcTsgA"
      },
      "source": [
        "## ResNet50 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4jGsgduTwAC"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-6.pkl')\n",
        "resnet50.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "predict(resnet50, data['test'], checkpoints + \"preds.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puqONOtDHEt4"
      },
      "source": [
        "# ResNet50 Experiment with Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y9P6GLSHJXq"
      },
      "source": [
        "## ResNet50 Training - Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj3MXlF6HRzC"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=5, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOW8DSeEHRl2"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=10, schedule={0:.001, 4:.0001, 8: .00001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2M3XbzhHZF4"
      },
      "source": [
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "losses = train(resnet50, data['train'], data['val'], epochs=20, schedule={0:.001, 4:.0001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PweyE1u4HP0i"
      },
      "source": [
        "## ResNet50 Test - Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-zw0ifzHeFq"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=True)\n",
        "resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-20.pkl')\n",
        "resnet50.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "predict(resnet50, data['test'], checkpoints + \"preds.csv\")zx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxjjrnjETp0x"
      },
      "source": [
        "# ResNet101 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBNaYlhxTtYe"
      },
      "source": [
        "## ResNet101 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9aD0guSV-cZ"
      },
      "source": [
        "resnet101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet101', pretrained=True)\n",
        "resnet101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet101, data['train'], data['val'], epochs=5, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8icy_CyTWOMX"
      },
      "source": [
        "resnet101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet101', pretrained=True)\n",
        "resnet101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet101, data['train'], data['val'], epochs=10, schedule={0:.01, 4:0.001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4KRIrlQWXNR"
      },
      "source": [
        "resnet101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet101', pretrained=True)\n",
        "resnet101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "losses = train(resnet101, data['train'], data['val'], epochs=20, schedule={0:.01, 4:0.001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRoe5WW9Tw5f"
      },
      "source": [
        "## ResNet101 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRttSMHnVy3L"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet101', pretrained=True)\n",
        "resnet101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-20.pkl')\n",
        "resnet101.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "predict(resnet101, data['test'], checkpoints + \"preds.csv\")zx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ef5VgApaHXy"
      },
      "source": [
        "# ResNet152 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMyt78qDaLHL"
      },
      "source": [
        "## ResNet152 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ifdk5oaKkS"
      },
      "source": [
        "resnet152 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
        "resnet152.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnet152, data['train'], data['val'], epochs=5, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nGxZCcQkaXZa"
      },
      "source": [
        "resnet152 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
        "resnet152.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnet152, data['train'], data['val'], epochs=10, schedule={0:.01, 6:.0001, 12:.00001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSlAw0Z6K5pp"
      },
      "source": [
        "resnet152 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
        "resnet152.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-18.pkl')\n",
        "losses = train(resnet152, data['train'], data['val'], epochs=25, schedule={0:.01, 4:.001}, lr=0.0001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUXBtehBh7C6"
      },
      "source": [
        "## ResNet152 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8CkzZxiCgc"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnet152 = torch.hub.load('pytorch/vision:v0.9.0', 'resnet152', pretrained=True)\n",
        "resnet152.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-25.pkl')\n",
        "resnet152.load_state_dict(state['net'])\n",
        "\n",
        "predict(resnet152, data['test'], checkpoints + \"preds.csv\")\n",
        "print(\"Finished creating .csv file!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS7vUyLQXMTY"
      },
      "source": [
        "# Wide ResNet50 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHVnYmlyXbf_"
      },
      "source": [
        "## Wide ResNet50 Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm9nMdgHXnv7"
      },
      "source": [
        "wide_resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'wide_resnet50_2', pretrained=True)\n",
        "wide_resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(wide_resnet50, data['train'], data['val'], epochs=5, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-TrqcUiYD3N"
      },
      "source": [
        "wide_resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'wide_resnet50_2', pretrained=True)\n",
        "wide_resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(wide_resnet50, data['train'], data['val'], epochs=10, schedule={0:.01, 4:.001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uah7m96GYZng"
      },
      "source": [
        "wide_resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'wide_resnet50_2', pretrained=True)\n",
        "wide_resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "losses = train(wide_resnet50, data['train'], data['val'], epochs=20, schedule={0:.01, 4:.001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gub5mawrXcZA"
      },
      "source": [
        "## Wide ResNet50 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhbIjtefYnW-"
      },
      "source": [
        "# Load model from checkpoint\n",
        "wide_resnet50 = torch.hub.load('pytorch/vision:v0.9.0', 'wide_resnet50_2', pretrained=True)\n",
        "wide_resnet50.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-20.pkl')\n",
        "wide_resnet50.load_state_dict(state['net'])\n",
        "\n",
        "predict(wide_resnet50, data['test'], checkpoints + \"preds.csv\")\n",
        "print(\"Finished creating .csv file!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7107HnR1VroI"
      },
      "source": [
        "# ResNext101 Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn3yi9QxW2-X"
      },
      "source": [
        "## ResNext101 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ED9iEOVn28"
      },
      "source": [
        "resnext101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "resnext101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "\n",
        "losses = train(resnext101, data['train'], data['val'], epochs=5, lr=0.01, decay=0.001, print_every=50, checkpoint_path=checkpoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_V-xQ8YV6vf"
      },
      "source": [
        "resnext101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "resnext101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-5.pkl')\n",
        "losses = train(resnext101, data['train'], data['val'], epochs=10, schedule={0:.01, 4:.001, 12:.0001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQOHoWyiWGKn"
      },
      "source": [
        "resnext101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "resnext101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-10.pkl')\n",
        "losses = train(resnext101, data['train'], data['val'], epochs=15, schedule={0:.01, 4:.001, 8:.0001}, lr=0.001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiEkSaeWnLl"
      },
      "source": [
        "resnext101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "resnext101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-15.pkl')\n",
        "losses = train(resnext101, data['train'], data['val'], epochs=25, schedule={0:.01, 4:.001, 8:.0001}, lr=0.0001, decay=0.001, print_every=50, checkpoint_path=checkpoints, state=state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y4cevTvMJBT"
      },
      "source": [
        "## ResNext101 Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYVlnFI85VpG"
      },
      "source": [
        "# Load model from checkpoint\n",
        "resnext101 = torch.hub.load('pytorch/vision:v0.9.0', 'resnext101_32x8d', pretrained=True)\n",
        "resnext101.fc = nn.Linear(2048, 555) # This will reinitialize the layer as well\n",
        "state = torch.load(checkpoints + 'checkpoint-28.pkl')\n",
        "resnext101.load_state_dict(state['net'])\n",
        "\n",
        "predict(resnext101, data['test'], checkpoints + \"preds.csv\")\n",
        "print(\"Finished creating .csv file!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}